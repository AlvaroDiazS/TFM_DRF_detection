{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"model_training","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sosjI7cDDm-f","executionInfo":{"status":"ok","timestamp":1654360047744,"user_tz":-120,"elapsed":15284,"user":{"displayName":"Alvaro DÃ­az Sanchez","userId":"11070108605821766022"}},"outputId":"89a00320-5c15-4f4b-c96b-fe7c23599db9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","source":["import tensorflow as tf\n","import keras\n","from tensorflow.keras.optimizers import Adam, SGD, Adadelta, Adagrad\n","from keras import Sequential, Model\n","from keras.models import load_model\n","from keras.utils import np_utils\n","from keras.metrics import Accuracy\n","from keras.preprocessing.image import ImageDataGenerator  \n","from keras.layers import (\n","    GlobalAveragePooling2D, Multiply, Flatten, Input,Lambda,\n","     Dense, Dropout, Conv2D, BatchNormalization, MaxPooling2D, Resizing)\n","from keras.callbacks import EarlyStopping\n","from keras.applications.vgg19 import VGG19\n","from keras.preprocessing import image\n","from keras.applications.vgg19 import preprocess_input\n","from keras import activations\n","from vis.utils import utils\n","\n","%pylab inline\n","import cv2\n","import glob\n","import os\n","import matplotlib.pylab as plt\n","import pickle\n","from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n","import random\n","import seaborn as sns \n","import shutil \n","import time\n","import numpy as np\n","\n","import pandas as pd"],"metadata":{"id":"k-eOK1wnKg2p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Funcion que genera los conjuntos de train y test de una carpeta concreta\n","def get_data(path, bt = 10):  \n","  train_generator = ImageDataGenerator(rotation_range=20,\n","                                       width_shift_range=0.2,\n","                                       height_shift_range=0.2,\n","                                       horizontal_flip=True,\n","                                       zoom_range = 0.2,\n","                                       shear_range = 0.2,\n","                                       vertical_flip = True ,\n","                                       preprocessing_function=preprocess_input)\n","  \n","  \n","  test_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n","\n","\n","  path_train = path + '/train'\n","  train_data = train_generator.flow_from_directory(directory= path_train,\n","                                                      class_mode='categorical',\n","                                                      shuffle = True, \n","                                                      batch_size = bt,\n","                                                      seed=21,\n","                                                      classes=['Normal', 'Fracture'], \n","                                                      target_size = (224,224)\n","                                                      )\n","  \n","  path_test = path + '/test'\n","  test_data = test_generator.flow_from_directory(directory= path_test,\n","                                                      class_mode='categorical',\n","                                                      shuffle = False,\n","                                                      batch_size = bt,\n","                                                      seed = 21,\n","                                                      classes=['Normal', 'Fracture'],\n","                                                      target_size = (224,224),\n","                                                      )\n","  \n","  return train_data, test_data"],"metadata":{"id":"jt2FLxXDKoUB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Definicion modelo \n","def get_model():\n","\n","  nn = VGG19(weights='imagenet', include_top=False, input_shape=(224,224,3))\n","  nn.trainable = False #congelar valores\n","\n","  model = Sequential()\n","  model.add(nn)\n","  model.add(Flatten(name = \"fla\"))\n","  model.add(Dropout(0.5, name = \"dro\")) \n","  model.add(Dense(2, activation = \"softmax\",name='predictions'))\n","\n","  return model"],"metadata":{"id":"A7LSPg96KqUo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Definicion funcion que entrena el modelo\n","def train_model(model, data,path_model, name, optimizer_type, learning_rate, batch_size): \n","\n","  opt = optimizer_type(learning_rate=learning_rate)\n","  model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[\"accuracy\"])\n","\n","  cb = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True, verbose = 0)\n","  \n","  history_model = model.fit(data,\n","                  epochs=10,\n","                  batch_size = batch_size,\n","                  callbacks=[cb],\n","                  verbose = 0)\n","\n","     \n","  model.save(path_model + 'weights_model/' + name + '.pkl')\n","  metrics=history_model.history\n","  f = open(path_model + 'metrics_model/' + name + '.pkl',\"wb\")\n","  pickle.dump(metrics,f)\n","  f.close()\n","\n","  return model"],"metadata":{"id":"9HEZtpj7KtyI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# funcion que calcula el accuracy del modelo\n","def model_accuracy(model, data):\n","  y_pred = model.predict(data)\n","  y_pred = np.argmax(y_pred, axis=1)\n","\n","  tn, fp, fn, tp =confusion_matrix(y_true =data.classes,y_pred =y_pred).ravel()\n","  return round((tn+tp)/(tn+fp+fn+tp),4)"],"metadata":{"id":"8l8W3hG2LibP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Declaracion de variables y entrenamiento de todos los modelos posibles\n","OPTIMIZERS =[Adam, SGD, Adadelta, Adagrad]\n","LEARNING_RATES = [0.001,0.01, 0.05,0.1]\n","BATCH_SIZE = [10,20,30,40]\n","\n","#nombres de las variables para guardar el modelo\n","OPTIMIZERS_NAME =[\"Adam\", \"SGD\", \"Adadelta\", \"Adagrad\"]\n","LEARNING_RATES_NAME = [\"0,001\",\"0,01\", \"0,05\",\"0,1\"]\n","\n","#vectores para guardar resultados\n","results_full = []\n","results_A = []\n","results_L = []\n","acc_full_max = 0\n","acc_A_max = 0\n","acc_L_max = 0\n","                   \n","i = 0\n","for op in OPTIMIZERS:\n","    j = 0\n","    for lr in LEARNING_RATES:\n","      k = 0\n","      for bt in BATCH_SIZE:\n","\n","        #cargar datos con el batch size apropiado\n","        train_full, test_full = get_data('/content/drive/MyDrive/TFM/PAC3_Modelos/BBDD/Preprocessed Wrist Fracture', bt = bt)\n","        train_A, test_A = get_data('/content/drive/MyDrive/TFM/PAC3_Modelos/BBDD/Preprocessed Wrist Fracture A View', bt = bt)\n","        train_L, test_L = get_data('/content/drive/MyDrive/TFM/PAC3_Modelos/BBDD/Preprocessed Wrist Fracture L View', bt = bt)\n","\n","        #creacion del model + entrenamiento\n","        model_name =  OPTIMIZERS_NAME[i] + '_' + LEARNING_RATES_NAME[j] + '_' +str(bt)\n","\n","        model = get_model()\n","        model_full = train_model(model = model,data = train_full,path_model = '/content/drive/MyDrive/TFM/PAC3_Modelos/Modelo_final/01_full_model/' ,name = model_name, optimizer_type = op,learning_rate = lr,batch_size = bt)\n","        model = get_model()\n","        model_A = train_model(model = model,data = train_A,path_model = '/content/drive/MyDrive/TFM/PAC3_Modelos/Modelo_final/02_A_model/' ,name = model_name, optimizer_type = op,learning_rate = lr,batch_size = bt)\n","        model = get_model()\n","        model_L = train_model(model = model,data = train_L,path_model = '/content/drive/MyDrive/TFM/PAC3_Modelos/Modelo_final/03_L_model/' ,name = model_name, optimizer_type = op,learning_rate = lr,batch_size = bt)\n","\n","        #evaludar modelo\n","        acc_full_model = model_accuracy(model_full,test_full)\n","        acc_A_model = model_accuracy(model_A,test_A)\n","        acc_L_model = model_accuracy(model_L,test_L)     \n","        \n","        #guardar valors      \n","        results_full.append([OPTIMIZERS_NAME[i],LEARNING_RATES[j],BATCH_SIZE[k],acc_full_model])\n","        results_A.append([OPTIMIZERS_NAME[i],LEARNING_RATES[j],BATCH_SIZE[k],acc_A_model])\n","        results_L.append([OPTIMIZERS_NAME[i],LEARNING_RATES[j],BATCH_SIZE[k],acc_L_model])\n","        k += 1\n","      j += 1\n","    i += 1\n","\n","#guardar resultatos\n","results_full = pd.DataFrame(results_full, columns =[\"optimizer\", \"learning_rate\",\"batch_size\", 'accuracy']) \n","results_full.to_csv(\"/content/drive/MyDrive/TFM/PAC3_Modelos/Modelo_final/results/GS_full.csv\",sep=';')\n","\n","results_A = pd.DataFrame(results_A, columns =[\"optimizer\", \"learning_rate\",\"batch_size\", 'accuracy'])\n","results_A.to_csv(\"/content/drive/MyDrive/TFM/PAC3_Modelos/Modelo_final/results/GS_A.csv\", sep=';')\n","\n","results_L = pd.DataFrame(results_L, columns =[\"optimizer\", \"learning_rate\",\"batch_size\", 'accuracy'])\n","results_L.to_csv(\"/content/drive/MyDrive/TFM/PAC3_Modelos/Modelo_final/results/GS_L.csv\", sep=';')"],"metadata":{"id":"mAeeRlzRNUTC"},"execution_count":null,"outputs":[]}]}